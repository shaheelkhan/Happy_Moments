{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "happy_moments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10x1hUbCIF-TTl_SRyby7edxeKVjkcZ3q",
      "authorship_tag": "ABX9TyMoBm2Db7u3CL6YgIUwM+/x"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjYZvX0MNTAk"
      },
      "source": [
        "#Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "aepc5lfgPBzn",
        "outputId": "63d88c10-6aa4-4c32-d7aa-0be23282f780"
      },
      "source": [
        "#Import the data\n",
        "happy_data = pd.read_csv('happy.csv')\n",
        "happy_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hmid</th>\n",
              "      <th>wid</th>\n",
              "      <th>reflection_period</th>\n",
              "      <th>original_hm</th>\n",
              "      <th>cleaned_hm</th>\n",
              "      <th>modified</th>\n",
              "      <th>num_sentence</th>\n",
              "      <th>ground_truth_category</th>\n",
              "      <th>predicted_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27673</td>\n",
              "      <td>2053</td>\n",
              "      <td>24h</td>\n",
              "      <td>I went on a successful date with someone I fel...</td>\n",
              "      <td>I went on a successful date with someone I fel...</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>affection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27674</td>\n",
              "      <td>2</td>\n",
              "      <td>24h</td>\n",
              "      <td>I was happy when my son got 90% marks in his e...</td>\n",
              "      <td>I was happy when my son got 90% marks in his e...</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>affection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27675</td>\n",
              "      <td>1936</td>\n",
              "      <td>24h</td>\n",
              "      <td>I went to the gym this morning and did yoga.</td>\n",
              "      <td>I went to the gym this morning and did yoga.</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>exercise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27676</td>\n",
              "      <td>206</td>\n",
              "      <td>24h</td>\n",
              "      <td>We had a serious talk with some friends of our...</td>\n",
              "      <td>We had a serious talk with some friends of our...</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>bonding</td>\n",
              "      <td>bonding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27677</td>\n",
              "      <td>6227</td>\n",
              "      <td>24h</td>\n",
              "      <td>I went with grandchildren to butterfly display...</td>\n",
              "      <td>I went with grandchildren to butterfly display...</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>affection</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    hmid   wid  ... ground_truth_category predicted_category\n",
              "0  27673  2053  ...                   NaN          affection\n",
              "1  27674     2  ...                   NaN          affection\n",
              "2  27675  1936  ...                   NaN           exercise\n",
              "3  27676   206  ...               bonding            bonding\n",
              "4  27677  6227  ...                   NaN          affection\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJqayB2TSEur",
        "outputId": "0372642f-950b-4ae9-d985-cc10ab9cee3f"
      },
      "source": [
        "#Check the shape of the dataset\n",
        "happy_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100535, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WynZ44KeV6ab",
        "outputId": "542bf2b5-28e3-406d-f608-4f053f8cc3c3"
      },
      "source": [
        "#Check the number of items in each of the class\n",
        "happy_data['predicted_category'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "affection           34168\n",
              "achievement         33993\n",
              "enjoy_the_moment    11144\n",
              "bonding             10727\n",
              "leisure              7458\n",
              "nature               1843\n",
              "exercise             1202\n",
              "Name: predicted_category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PwsUvan68C_",
        "outputId": "6cae0919-71df-4973-e4b3-747308a4c5e3"
      },
      "source": [
        "#Check count for each sentence count\n",
        "happy_data['num_sentence'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     83711\n",
              "2      9542\n",
              "3      3847\n",
              "4      1624\n",
              "5       821\n",
              "6       336\n",
              "7       183\n",
              "8       107\n",
              "10       68\n",
              "9        61\n",
              "11       35\n",
              "13       26\n",
              "12       21\n",
              "16       17\n",
              "18       17\n",
              "14       14\n",
              "17       14\n",
              "19       12\n",
              "21       10\n",
              "25        7\n",
              "15        7\n",
              "23        7\n",
              "24        5\n",
              "26        5\n",
              "22        4\n",
              "29        3\n",
              "31        3\n",
              "30        3\n",
              "20        3\n",
              "27        2\n",
              "32        2\n",
              "37        2\n",
              "40        2\n",
              "56        1\n",
              "46        1\n",
              "53        1\n",
              "51        1\n",
              "48        1\n",
              "69        1\n",
              "35        1\n",
              "45        1\n",
              "44        1\n",
              "42        1\n",
              "58        1\n",
              "34        1\n",
              "28        1\n",
              "60        1\n",
              "Name: num_sentence, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvzvKWPf7cIt",
        "outputId": "0657464d-74f7-4cf2-ee19-5780bea5922e"
      },
      "source": [
        "#We'll use only those rows which has 10 or less sentences as others has less count\n",
        "new_data = happy_data[happy_data['num_sentence'] <= 10]\n",
        "new_data['num_sentence'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     83711\n",
              "2      9542\n",
              "3      3847\n",
              "4      1624\n",
              "5       821\n",
              "6       336\n",
              "7       183\n",
              "8       107\n",
              "10       68\n",
              "9        61\n",
              "Name: num_sentence, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coKkubL77-1h"
      },
      "source": [
        "#Encode the response variable\n",
        "class_map = {\n",
        "    \"affection\" : 0,\n",
        "    \"achievement\"  : 1,       \n",
        "    \"bonding\" : 2,    \n",
        "    \"enjoy_the_moment\" : 3,     \n",
        "    \"leisure\"  : 4,    \n",
        "    \"nature\" : 5,    \n",
        "    \"exercise\" : 6\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R920ggd8U-J"
      },
      "source": [
        "new_data['predicted_category'] = new_data['predicted_category'].map(class_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "d87vtgOZ8dm5",
        "outputId": "be86dcf3-6f41-4597-f36e-03e3f77d749b"
      },
      "source": [
        "new_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hmid</th>\n",
              "      <th>wid</th>\n",
              "      <th>reflection_period</th>\n",
              "      <th>original_hm</th>\n",
              "      <th>cleaned_hm</th>\n",
              "      <th>modified</th>\n",
              "      <th>num_sentence</th>\n",
              "      <th>ground_truth_category</th>\n",
              "      <th>predicted_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27673</td>\n",
              "      <td>2053</td>\n",
              "      <td>24h</td>\n",
              "      <td>I went on a successful date with someone I fel...</td>\n",
              "      <td>I went on a successful date with someone I fel...</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27674</td>\n",
              "      <td>2</td>\n",
              "      <td>24h</td>\n",
              "      <td>I was happy when my son got 90% marks in his e...</td>\n",
              "      <td>I was happy when my son got 90% marks in his e...</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27675</td>\n",
              "      <td>1936</td>\n",
              "      <td>24h</td>\n",
              "      <td>I went to the gym this morning and did yoga.</td>\n",
              "      <td>I went to the gym this morning and did yoga.</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27676</td>\n",
              "      <td>206</td>\n",
              "      <td>24h</td>\n",
              "      <td>We had a serious talk with some friends of our...</td>\n",
              "      <td>We had a serious talk with some friends of our...</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>bonding</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27677</td>\n",
              "      <td>6227</td>\n",
              "      <td>24h</td>\n",
              "      <td>I went with grandchildren to butterfly display...</td>\n",
              "      <td>I went with grandchildren to butterfly display...</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    hmid   wid  ... ground_truth_category predicted_category\n",
              "0  27673  2053  ...                   NaN                  0\n",
              "1  27674     2  ...                   NaN                  0\n",
              "2  27675  1936  ...                   NaN                  6\n",
              "3  27676   206  ...               bonding                  2\n",
              "4  27677  6227  ...                   NaN                  0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8nL3ko69vGY"
      },
      "source": [
        "**Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86a8uC-r84kS",
        "outputId": "58360f94-3937-48d8-9404-fa68f37d2058"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l02lNsPhBDIW"
      },
      "source": [
        "preprocessed_text = []\n",
        "happy_texts = new_data['cleaned_hm'].values.tolist()\n",
        "for item in happy_texts:\n",
        "\n",
        "  #Remove the punctuations\n",
        "  new_text = re.sub('[^a-zA-Z]',' ',item)\n",
        "\n",
        "  #Lower the cases\n",
        "  new_text = new_text.lower()\n",
        "\n",
        "  #Split the words\n",
        "  new_text = new_text.split()\n",
        "\n",
        "  #Remove Stopwords\n",
        "  new_text = [word for word in new_text if word not in stopwords.words('english')]\n",
        "  \n",
        "  preprocessed_text.append(new_text)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmWSBi9On4wR"
      },
      "source": [
        "#Save the preprocessed text\n",
        "file = 'preprocessed_text.pkl'\n",
        "pickle.dump(preprocessed_text,open(file,'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DjldFFGn6N7"
      },
      "source": [
        "#Load the text preprocessed data\n",
        "preprocessed_text = pickle.load(open(\"preprocessed_text.pkl\",\"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asMP_IBJooWx",
        "outputId": "a28d1c9b-0901-491b-edfb-d9f0c24cb3d0"
      },
      "source": [
        "preprocessed_text[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['went', 'successful', 'date', 'someone', 'felt', 'sympathy', 'connection'],\n",
              " ['happy', 'son', 'got', 'marks', 'examination']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KSCOjwlorty",
        "outputId": "3b897f80-8022-46e7-b3e6-c1c2e913c827"
      },
      "source": [
        "len(preprocessed_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBtBjDBKuSB9",
        "outputId": "fe339686-541d-474c-ee8b-5766b005365e"
      },
      "source": [
        "#Findout the sentence which has maxm words\n",
        "max_words = 1\n",
        "\n",
        "for w in preprocessed_text:\n",
        "  if len(w) > max_words:\n",
        "    max_words = len(w)\n",
        "\n",
        "print('Maxm no: of words in a sentence: {}'.format(max_words)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maxm no: of words in a sentence: 129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m-RYxJeo6xG"
      },
      "source": [
        "#Findout number of words in each sentences\n",
        "num_words = []\n",
        "for word in preprocessed_text:\n",
        "  words = len(word)\n",
        "  num_words.append(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM7EiIulmD7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017ed4f7-0c48-443c-827f-b73595431cd9"
      },
      "source": [
        "from collections import Counter\n",
        "sorted(Counter(num_words).items(),key = lambda x: x[1],reverse=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5, 12571),\n",
              " (6, 12125),\n",
              " (4, 11403),\n",
              " (7, 10025),\n",
              " (3, 8446),\n",
              " (8, 8015),\n",
              " (9, 6403),\n",
              " (10, 4973),\n",
              " (11, 3797),\n",
              " (2, 3316),\n",
              " (12, 2937),\n",
              " (13, 2452),\n",
              " (14, 1941),\n",
              " (15, 1685),\n",
              " (16, 1354),\n",
              " (17, 1105),\n",
              " (18, 822),\n",
              " (19, 756),\n",
              " (20, 664),\n",
              " (21, 553),\n",
              " (22, 503),\n",
              " (24, 448),\n",
              " (23, 443),\n",
              " (25, 313),\n",
              " (28, 265),\n",
              " (26, 263),\n",
              " (27, 225),\n",
              " (29, 208),\n",
              " (30, 190),\n",
              " (31, 157),\n",
              " (1, 147),\n",
              " (32, 129),\n",
              " (34, 126),\n",
              " (33, 116),\n",
              " (35, 114),\n",
              " (37, 88),\n",
              " (36, 80),\n",
              " (38, 79),\n",
              " (40, 78),\n",
              " (51, 77),\n",
              " (41, 65),\n",
              " (42, 62),\n",
              " (39, 62),\n",
              " (47, 61),\n",
              " (53, 53),\n",
              " (43, 45),\n",
              " (46, 40),\n",
              " (44, 39),\n",
              " (45, 38),\n",
              " (49, 38),\n",
              " (48, 31),\n",
              " (61, 26),\n",
              " (50, 26),\n",
              " (63, 23),\n",
              " (52, 20),\n",
              " (54, 20),\n",
              " (62, 20),\n",
              " (59, 17),\n",
              " (55, 16),\n",
              " (64, 16),\n",
              " (57, 15),\n",
              " (56, 15),\n",
              " (66, 14),\n",
              " (60, 13),\n",
              " (65, 12),\n",
              " (58, 8),\n",
              " (71, 8),\n",
              " (79, 8),\n",
              " (129, 7),\n",
              " (125, 7),\n",
              " (80, 6),\n",
              " (69, 6),\n",
              " (72, 6),\n",
              " (75, 6),\n",
              " (87, 6),\n",
              " (68, 5),\n",
              " (73, 5),\n",
              " (78, 5),\n",
              " (67, 4),\n",
              " (74, 4),\n",
              " (124, 4),\n",
              " (95, 3),\n",
              " (70, 3),\n",
              " (89, 3),\n",
              " (77, 2),\n",
              " (96, 2),\n",
              " (76, 2),\n",
              " (97, 1),\n",
              " (84, 1),\n",
              " (114, 1),\n",
              " (0, 1),\n",
              " (103, 1),\n",
              " (98, 1),\n",
              " (113, 1),\n",
              " (93, 1),\n",
              " (88, 1),\n",
              " (85, 1),\n",
              " (104, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YykoA9JH3RW"
      },
      "source": [
        "**Applying Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE9ktsJxE3pp"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBufWmHntLza"
      },
      "source": [
        "#Define number of dimensions into which each word is vectorized\n",
        "embedding_dim = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD6mtyYtH-YC"
      },
      "source": [
        "w2v_model = gensim.models.Word2Vec(sentences=preprocessed_text,\n",
        "                                   size=embedding_dim,\n",
        "                                   window=5,\n",
        "                                   workers=4,\n",
        "                                   min_count=1)\n",
        "word_vocab = list(w2v_model.wv.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfy9FzWWn_Vi",
        "outputId": "69616c6c-acb2-4086-f8c2-5fba0f7228da"
      },
      "source": [
        "#len(word_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23628"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLbxzsFgMSB3"
      },
      "source": [
        "**Save the word vectors for later use**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_H03pbAJK6n"
      },
      "source": [
        "w2v_model.wv.save_word2vec_format(\"happy_w2v.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usyTSZEVob1g"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpncgTK3Sdrs"
      },
      "source": [
        "# Create a tokenizer object\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_text)\n",
        "\n",
        "#Get index position of each unique word in preprocessed_text\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "#Convert the words in each sentence into its correponding index position\n",
        "#each sentence will be encoded like [4,611,205,41,9566]\n",
        "sequences = tokenizer.texts_to_sequences(preprocessed_text)\n",
        "\n",
        "#Pad the sequences to be the same length.\n",
        "max_length = 54\n",
        "padded_data = pad_sequences(sequences=sequences,maxlen=max_length,padding='post')\n",
        "labels = new_data['predicted_category'].values\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hRzoq8Fv__a"
      },
      "source": [
        "**Split the data into a training set and a validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP3ulenmwlxI"
      },
      "source": [
        "indices = np.arange(padded_data.shape[0])\n",
        "\n",
        "#Assign a seed for reproducibility\n",
        "np.random.seed(99)\n",
        "np.random.shuffle(indices)\n",
        "padded_data = padded_data[indices]\n",
        "labels = labels[indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf9rYuyTqOkx"
      },
      "source": [
        "#Convert labels into a 1D matrix\n",
        "max_label_no = np.max(labels) + 1\n",
        "labels = np.eye(max_label_no)[labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etw-35FcTzJS",
        "outputId": "c0194406-e823-4cf8-e2ad-90f16a2ca447"
      },
      "source": [
        "#Do 80-20 split\n",
        "validation_ratio = 0.2\n",
        "num_validation_samples = int(validation_ratio*padded_data.shape[0])\n",
        "\n",
        "x_train = padded_data[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = padded_data[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]\n",
        "\n",
        "print('Shape of x_train:', x_train.shape)\n",
        "print('Shape of y_train:', y_train.shape)\n",
        "\n",
        "print('Shape of x_val:', x_val.shape)\n",
        "print('Shape of y_val:', y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train: (80240, 54)\n",
            "Shape of y_train: (80240, 7)\n",
            "Shape of x_val: (20060, 54)\n",
            "Shape of y_val: (20060, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJLloHNgzeGP"
      },
      "source": [
        "**Create a weight matrix for words in training docs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VAsOgm4zdRj"
      },
      "source": [
        "#Load the embedded file into memory as a dictionary of word to embedding array.\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join('', 'happy_w2v.txt'),  encoding = \"utf-8\")\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  vec = np.asarray(values[1:])\n",
        "  embeddings_index[word] = vec\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EQ-X13ZVMot"
      },
      "source": [
        "#Use embedding_index dictionary and word_index to compute the embedding matrix:\n",
        "input_dim = len(word_index)+1\n",
        "embedding_matrix = np.zeros((input_dim,embedding_dim))\n",
        "\n",
        "for word,i in word_index.items():\n",
        "  if i > (len(word_index)+1):\n",
        "    continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z79_pXX26Ex"
      },
      "source": [
        "**Build the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GwcS4DxWROm",
        "outputId": "63be94fa-6d56-478b-b09c-f20728eb19d1"
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(input_dim=input_dim,\n",
        "                            output_dim=embedding_dim,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length = max_length,\n",
        "                            trainable=False\n",
        "                            )\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(units=80,dropout=0.2,recurrent_dropout=0.2))\n",
        "model.add(Dense(units=7,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 54, 100)           2362900   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 96)                75648     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7)                 679       \n",
            "=================================================================\n",
            "Total params: 2,439,227\n",
            "Trainable params: 76,327\n",
            "Non-trainable params: 2,362,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaxDwXrD41n6"
      },
      "source": [
        "**Save the best model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UBhJ-xL408C"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath = 'lstm-model-weights-{epoch:03d}-{val_accuracy:03f}.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, verbose=1, monitor='val_accuracy',save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVhebYnl5Jw4"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXyFyo25V8_h",
        "outputId": "b61660b0-9a40-47f1-dd26-9de8224d7c09"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=25, validation_data=(x_val, y_val), callbacks=callbacks_list)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 1.0584 - accuracy: 0.5812\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.78923, saving model to lstm96-model-weights-001-0.789232.h5\n",
            "402/402 [==============================] - 75s 186ms/step - loss: 1.0584 - accuracy: 0.5812 - val_loss: 0.7144 - val_accuracy: 0.7892\n",
            "Epoch 2/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.7916\n",
            "Epoch 00002: val_accuracy improved from 0.78923 to 0.80718, saving model to lstm96-model-weights-002-0.807178.h5\n",
            "402/402 [==============================] - 75s 185ms/step - loss: 0.6429 - accuracy: 0.7916 - val_loss: 0.6183 - val_accuracy: 0.8072\n",
            "Epoch 3/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.8181\n",
            "Epoch 00003: val_accuracy improved from 0.80718 to 0.82871, saving model to lstm96-model-weights-003-0.828714.h5\n",
            "402/402 [==============================] - 74s 183ms/step - loss: 0.5519 - accuracy: 0.8181 - val_loss: 0.5213 - val_accuracy: 0.8287\n",
            "Epoch 4/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.8295\n",
            "Epoch 00004: val_accuracy did not improve from 0.82871\n",
            "402/402 [==============================] - 72s 179ms/step - loss: 0.5081 - accuracy: 0.8295 - val_loss: 0.5878 - val_accuracy: 0.8018\n",
            "Epoch 5/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.8404\n",
            "Epoch 00005: val_accuracy improved from 0.82871 to 0.83978, saving model to lstm96-model-weights-005-0.839781.h5\n",
            "402/402 [==============================] - 75s 186ms/step - loss: 0.4727 - accuracy: 0.8404 - val_loss: 0.4748 - val_accuracy: 0.8398\n",
            "Epoch 6/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.8455\n",
            "Epoch 00006: val_accuracy did not improve from 0.83978\n",
            "402/402 [==============================] - 72s 180ms/step - loss: 0.4495 - accuracy: 0.8455 - val_loss: 0.4581 - val_accuracy: 0.8383\n",
            "Epoch 7/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8507\n",
            "Epoch 00007: val_accuracy improved from 0.83978 to 0.84920, saving model to lstm96-model-weights-007-0.849202.h5\n",
            "402/402 [==============================] - 73s 182ms/step - loss: 0.4319 - accuracy: 0.8507 - val_loss: 0.4296 - val_accuracy: 0.8492\n",
            "Epoch 8/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.8550\n",
            "Epoch 00008: val_accuracy improved from 0.84920 to 0.86002, saving model to lstm96-model-weights-008-0.860020.h5\n",
            "402/402 [==============================] - 74s 185ms/step - loss: 0.4161 - accuracy: 0.8550 - val_loss: 0.4157 - val_accuracy: 0.8600\n",
            "Epoch 9/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8572\n",
            "Epoch 00009: val_accuracy did not improve from 0.86002\n",
            "402/402 [==============================] - 72s 179ms/step - loss: 0.4029 - accuracy: 0.8572 - val_loss: 0.4049 - val_accuracy: 0.8581\n",
            "Epoch 10/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3913 - accuracy: 0.8609\n",
            "Epoch 00010: val_accuracy improved from 0.86002 to 0.86087, saving model to lstm96-model-weights-010-0.860867.h5\n",
            "402/402 [==============================] - 73s 182ms/step - loss: 0.3913 - accuracy: 0.8609 - val_loss: 0.3959 - val_accuracy: 0.8609\n",
            "Epoch 11/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8626\n",
            "Epoch 00011: val_accuracy did not improve from 0.86087\n",
            "402/402 [==============================] - 73s 182ms/step - loss: 0.3826 - accuracy: 0.8626 - val_loss: 0.3981 - val_accuracy: 0.8595\n",
            "Epoch 12/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 0.8656\n",
            "Epoch 00012: val_accuracy improved from 0.86087 to 0.86306, saving model to lstm96-model-weights-012-0.863061.h5\n",
            "402/402 [==============================] - 74s 184ms/step - loss: 0.3741 - accuracy: 0.8656 - val_loss: 0.3864 - val_accuracy: 0.8631\n",
            "Epoch 13/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8672\n",
            "Epoch 00013: val_accuracy did not improve from 0.86306\n",
            "402/402 [==============================] - 72s 179ms/step - loss: 0.3663 - accuracy: 0.8672 - val_loss: 0.3975 - val_accuracy: 0.8579\n",
            "Epoch 14/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.8695\n",
            "Epoch 00014: val_accuracy improved from 0.86306 to 0.86815, saving model to lstm96-model-weights-014-0.868146.h5\n",
            "402/402 [==============================] - 74s 183ms/step - loss: 0.3597 - accuracy: 0.8695 - val_loss: 0.3771 - val_accuracy: 0.8681\n",
            "Epoch 15/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.8699\n",
            "Epoch 00015: val_accuracy did not improve from 0.86815\n",
            "402/402 [==============================] - 72s 180ms/step - loss: 0.3549 - accuracy: 0.8699 - val_loss: 0.3947 - val_accuracy: 0.8545\n",
            "Epoch 16/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8723\n",
            "Epoch 00016: val_accuracy did not improve from 0.86815\n",
            "402/402 [==============================] - 72s 180ms/step - loss: 0.3482 - accuracy: 0.8723 - val_loss: 0.3847 - val_accuracy: 0.8644\n",
            "Epoch 17/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.8742\n",
            "Epoch 00017: val_accuracy improved from 0.86815 to 0.86839, saving model to lstm96-model-weights-017-0.868395.h5\n",
            "402/402 [==============================] - 73s 183ms/step - loss: 0.3419 - accuracy: 0.8742 - val_loss: 0.3705 - val_accuracy: 0.8684\n",
            "Epoch 18/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3363 - accuracy: 0.8760\n",
            "Epoch 00018: val_accuracy did not improve from 0.86839\n",
            "402/402 [==============================] - 72s 180ms/step - loss: 0.3363 - accuracy: 0.8760 - val_loss: 0.3795 - val_accuracy: 0.8656\n",
            "Epoch 19/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.8767\n",
            "Epoch 00019: val_accuracy improved from 0.86839 to 0.86904, saving model to lstm96-model-weights-019-0.869043.h5\n",
            "402/402 [==============================] - 75s 185ms/step - loss: 0.3359 - accuracy: 0.8767 - val_loss: 0.3611 - val_accuracy: 0.8690\n",
            "Epoch 20/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8796\n",
            "Epoch 00020: val_accuracy improved from 0.86904 to 0.86939, saving model to lstm96-model-weights-020-0.869392.h5\n",
            "402/402 [==============================] - 74s 185ms/step - loss: 0.3278 - accuracy: 0.8796 - val_loss: 0.3775 - val_accuracy: 0.8694\n",
            "Epoch 21/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.8796\n",
            "Epoch 00021: val_accuracy improved from 0.86939 to 0.86994, saving model to lstm96-model-weights-021-0.869940.h5\n",
            "402/402 [==============================] - 74s 185ms/step - loss: 0.3256 - accuracy: 0.8796 - val_loss: 0.3703 - val_accuracy: 0.8699\n",
            "Epoch 22/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.8820\n",
            "Epoch 00022: val_accuracy did not improve from 0.86994\n",
            "402/402 [==============================] - 74s 184ms/step - loss: 0.3189 - accuracy: 0.8820 - val_loss: 0.3712 - val_accuracy: 0.8662\n",
            "Epoch 23/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.8814\n",
            "Epoch 00023: val_accuracy did not improve from 0.86994\n",
            "402/402 [==============================] - 72s 179ms/step - loss: 0.3168 - accuracy: 0.8814 - val_loss: 0.3769 - val_accuracy: 0.8659\n",
            "Epoch 24/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 0.8843\n",
            "Epoch 00024: val_accuracy improved from 0.86994 to 0.87208, saving model to lstm96-model-weights-024-0.872084.h5\n",
            "402/402 [==============================] - 73s 182ms/step - loss: 0.3120 - accuracy: 0.8843 - val_loss: 0.3625 - val_accuracy: 0.8721\n",
            "Epoch 25/25\n",
            "402/402 [==============================] - ETA: 0s - loss: 0.3086 - accuracy: 0.8846\n",
            "Epoch 00025: val_accuracy did not improve from 0.87208\n",
            "402/402 [==============================] - 75s 187ms/step - loss: 0.3086 - accuracy: 0.8846 - val_loss: 0.3649 - val_accuracy: 0.8691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4e44da668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vA58rBN6VCz"
      },
      "source": [
        "**Load the weights of best model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRaT5Lby6UhE",
        "outputId": "db43b81a-8e58-4a71-ad58-139168a38aa2"
      },
      "source": [
        "filepath = 'lstm-model-weights-022-0.875972.h5'\n",
        "model = load_model(filepath=filepath)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 54, 100)           2362900   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 80)                57920     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7)                 567       \n",
            "=================================================================\n",
            "Total params: 2,421,387\n",
            "Trainable params: 58,487\n",
            "Non-trainable params: 2,362,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE0EQNgmIRoV"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "valW_nNicKSy",
        "outputId": "084f812b-77d8-4934-d0e5-e95db0fde529"
      },
      "source": [
        "#Prediction for a random single value\n",
        "index_position = np.random.randint(len(y_val))\n",
        "prediction = np.argmax(model.predict(x_val[index_position:index_position+1]),axis=-1)\n",
        "predicted_matrix = np.eye(max_label_no)[prediction]\n",
        "print('Actual Label:-',y_val[index_position:index_position+1])\n",
        "print('Predicted Label:-',predicted_matrix)\n",
        "print(\"----------\")\n",
        "for i,k in class_map.items():\n",
        "  if k == np.argmax(y_val[index_position:index_position+1]):\n",
        "    print(\"Acutal reason for happiness is {}\".format(i))\n",
        "  if k == prediction[0]:\n",
        "    print(\"Predicted reason for happiness is {}\".format(i))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Label:- [[0. 0. 0. 1. 0. 0. 0.]]\n",
            "Predicted Label:- [[0. 0. 0. 1. 0. 0. 0.]]\n",
            "----------\n",
            "Acutal reason for happiness is enjoy_the_moment\n",
            "Predicted reason for happiness is enjoy_the_moment\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}